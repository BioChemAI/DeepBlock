random_seed: 20230112
warm_batch_size: 8
batch_size: 8
valid_batch_size: 8
num_workers: 0

x_max_len: 30
c_max_len: 1000

# https://github.com/facebookresearch/esm#available
# esm_model_name: "esm2_t33_650M_UR50D"
esm_model_name: "esm2_t6_8M_UR50D"

# Crossdocked has its own test set
split_pro:
    train: 0.8
    valid: 0.2

use_pretrain_frag_vector: false

## Model

# x_input_dim: Auto detect from x_vocab
x_emb_dim: 128

x_enc_hid_dim: 256
x_enc_hid_layers: 3

x_dec_hid_dim: 256
x_dec_hid_layers: 3

x_dropout: 0.25
x_bidirectional: false

# c_input_dim: Auto detect from esm_model
c_emb_dim: 256
c_eng_hid_dim: 256
c_dropout: 0.25

h_hid_dim: 256
h_dropout: 0.25

latent_dim: 128

bow_hid_dim: 256
bow_dropout: 0.25

## Train

max_epochs: 200
optim_lr: 1.0e-3

bow_weight: 1
rel_weight: 1

esm_cache_enable: true
use_esm_warm: true
move_esm_model_to_cpu_after_warm: true

rel_fn_type: "exp"

# optim_lr_scheduler:
#     mode: StepLR
#     value:
#         step_size: 10
#         gamma: 0.5

optim_lr_scheduler:
    mode: MultiStepLR
    value:
        milestones: [180]
        gamma: 0.1

clip_max_norm: 1.0e+3

# beta_vae: # !!!! TEST ONLY !!!!
#     mode: fix
#     value: 0

beta_vae:
    mode: fix
    value: 1.0e-3

# beta_vae:
#     mode: annealing
#     value:
#         cycle: 0
#         min_point: 0
#         max_point: 200
#         min_beta: 1.0e-5
#         max_beta: 1.0e-1

show_tqdm: true
c_attend: true
